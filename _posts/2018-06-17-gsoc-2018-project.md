---
layout: post
title: GSOC 2018 Project
date: 2018-06-17
---
## Title
Building Deep Predictive Models for Predicting GPS TEC Maps

## Contents
1. GSoC 2018 Project
   - Abstract
   - Broad Steps
2. People
3. Infrastructure
4. Phase 1
   - Timeline 1: May 14 to May 28
     - Exploring GPS TEC Maps and OMNI IMF data
     - Plotting TEC Maps
     - Specifications of ST-ResNet architecture
   - Timeline 2: May 29 to June 11
     - Input Data Pipeline
     - Generating Input Data Points
     - Implementing ST-ResNet Architecture in Tensorflow
   - Timeline 3: June 12 to June 17
     - Improving Data Pipeline  
     - Tuning ST-ResNet model and Plotting of Results
5. Phase 2
   - Timeline 4: June 18 to June 26
     - Getting the difference and channel wise TEC map plots
     - Error plots based on difference plots for further analysis
   - Timeline 5: June 27 to July 4
     - OMNI IMF data preprocessing
     - Implementing GRU encoder module
     - Results comparison with and without exogenous module
   - Timeline 6: July 5 to July 9 
     - Modifying the code for predicting the next one hour (block) TEC maps
     - Reporting the results on block prediction
6. Phase 3  
7. Future Work
8. References

## Abstract
GPS TEC Map (Global Positioning System - Total Electron Count) is an important quantity of the ionosphere for analysis of space weather. Building an accurate predictive model for TEC maps can help in anticipating adverse ionospheric effects (ex: due to a solar storm), thereby safeguarding critical communication, energy and navigation infrastructure. In this work, we employ a deep learning approach to predict TEC maps using deep Spatio-Temporal Residual Networks (ST-ResNets), the first attempted work of its kind, by focusing on the North American region. To obtain a contextual awareness of other space weather indicators during prediction, we also use exogenous data including OMNI IMF data (By, Bz, Vx, Np). Our model predicts TEC maps for the next hour and beyond, at a time resolution of five minutes, providing state-of-the-art prediction accuracy. Towards explainable Artificial Intelligence (AI), especially in deep learning models, we provide extensive visualizations of the outputs from our convolutional networks in all three branches (closeness, period and trend) for better analysis and insight. In the future, we aim to demonstrate the effectiveness and robustness of our model in predicting extremely rare solar storms, a challenging task given the insufficient training data for such events.

## Project Outline
<table>
<thead>

<tr>
<th>S.No.</th>
<th>Step</th>
<th>Status</th>
<th>Date</th>
</tr>
</thead>

<tbody>

<tr>
<td></td>
<th>Phase 1</th>
<td></td>
<td></td>
</tr>

<tr>
<td>1</td>
<td>Dataset exploration: plotting TEC</td>
<td> <span style="color:green"> DONE </span> </td>
<td>May 14</td>
</tr>

<tr>
<td>2</td>
<td>Dataset preprocessing: missing values</td>
<td> <span style="color:green"> DONE </span> </td>
<td>May 24</td>
</tr>

<tr>
<td>3</td>
<td>Input pipeline: closeness, period, trend</td>
<td> <span style="color:green"> DONE </span> </td>
<td>May 28</td>
</tr>

<tr>
<td>4</td>
<td>Model: ST-ResNet in Tensoflow</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 2</td>
</tr>

<tr>
<td>5</td>
<td>Model debugging</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 12</td>
</tr>

<tr>
<td>6</td>
<td>Results & plots of output TEC maps</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 12</td>
</tr>

<tr>
<td></td>
<th>Phase 2</th>
<td></td>
<td></td>
</tr>

<tr>
<td>7</td>
<td>Difference and Channel wise TEC map plots</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 19</td>
</tr>

<tr>
<td>8</td>
<td>Error plots for analysis</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 22</td>
</tr>

<tr>
<td>9</td>
<td>OMNI IMF data preprocessing</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 27</td>
</tr>

<tr>
<td>10</td>
<td>GRU encoder module</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 27</td>
</tr>

<tr>
<td>11</td>
<td>Improved results with IMF data</td>
<td> <span style="color:green"> DONE </span> </td>
<td>July 4</td>
</tr>

<tr>
<td>12</td>
<td>Block prediction (next one hour)</td>
<td> <span style="color:green"> DONE </span> </td>
<td>July 9</td>
</tr>

</tbody>

</table>


## People 
<ul>
<li>Sneha Singhania (sneha3295[at]gmail[dot]com)</li>
<li>Bharat Kunduri (bharatr[at]vt[dot]edu)</li>
<li>Muhammad Rafiq (rafiq[at]vt[dot]edu)</li>
</ul> 

## Infrastructure
We have used the HPCC system available at Virginia Tech for training the deep learning models on the entire dataset and Google Colab free GPU for training the model on a very small sample of the dataset. I'm highly thankful to the Space@VT organisation for arranging such a high end resource which was very helpful for training and testing various models.

## Phase 1
In the first phase of the project, the TEC maps and IMF data are explored. The deep learning model ST-ResNet is designed and implemented in Tensorflow. The model is also trained on a minimal sample of the dataset and preliminary results are reported.

### Timeline 1: May 14 to May 28
* Read about GPS TEC Maps, IMF data and other geomagnetic indices  
* Plotting the TEC Maps
* Discussion on the specifications of ST-ResNet Architecture

### GPS TEC Maps
TEC is the total number of electrons integrated between two points, along a tube of one meter squared cross section. It is a descriptive quantity for the ionosphere of the Earth atmosphere. It can be used for anticipating adverse ionospheric events like solar storms. For this project, we use GPS TEC Maps provided by the MIT Haystack Observatory (Madrigal database). This data is further pre-processed using techniques like median filtering. The TEC maps in its original form and in pre-processed form using median filtering is available at the SuperDARN database of Virginia Tech. For our project, we focus using the median filtered TEC maps. 

The TEC maps are stored in a tablular format in text file format. The major columns present in the data are date & time, magnetic latitude, magnetic longitude, TEC values, degree of magnetic latitude resolution and degree of magnetic longitude resoltion. The TEC values are recorded at a resolution of five minutes. We focus on the North-American sector of the TEC maps whose magnetic latitude lies in the range [15, 89] and magnetic longitude lies in the range [250, 360] and [0, 34]. From each text file, we read the TEC values in the given ranges and store it in separate numpy arrays of shape (75, 73).

We also plot TEC maps using the matplotlib library for better understanding. Visualization of TEC maps helps in understanding the spatial- temporal patterns present and can be used further for designing the specifics of the deep learning model. A sample plot of TEC map is shown in the figure below.

| ![]({{site.url}}/assets/sample_tec.png) |
|:--:| 
| **Figure 1: Sample TEC Plot** |

### IMF Data
Along with the TEC maps, we use other exogenous data including the OMNI IMF data for better model prediction. The list of exogenous variables that can be used are as follows:
* AU index, AL index (Auroral index horizontal component disturbances)
* Sym-H index, AsyH index (longitudinally symmetric/asymmetric disturbance index)
* Bz - OMNI IMF z component
* By - OMNI IMF y component
* Vx, np (proton ratio), f10.7 (daily flux density), dipole tilt

### Motivation
The presence of complex spatial and temporal properties in the TEC maps leads us to design deep learning based neural network models. Neural networks form high-dimensional abstract feature representation of the input data and use them for better TEC map predictions. The availability of large scale input TEC maps can be used for obtaining a generalized predictive model. We use the spatial properties of a TEC map and the temporal properties between the TEC maps are used for designing our model called Spatio-Temporal Residual Networks.

### ST-ResNet Architecture
Spatio-Temporal Residual Networks (ST-ResNet) is a deep learning model build using Residual Networks. Residual networks (ResNet), variant of Convolutional Neural Networks (CNNs), is a 152 layer network architecture generally used for tasks like classification, detection, and localization of objects. It had won ImageNet Large Scale Visual Recognition Competition (ILSVRC) 2015 challenge and have been used extensively since then. In the deep learning literatute, neural networks suffer from vanishing gradient problem as we keep increasing depth of the model. ResNet overcomes this problem with the help of residual links or skip connections. Deep residual networks helps in creating complex abstract features which leads to better model results.

ST-ResNet consists of three ResNet modules and a Gated Recurrent Unit (GRU) encoder module. The spatial properties of past TEC maps are captured by the convolution operation of the residual network. Further, the temporal properties of past maps are divided into closeness(recent), period(near) and trend(distant), and are captured by three separate residual network branches. As the name suggests, the closeness module takes the input TEC maps present in the recent past (eg. at time resolution of five minutes), period module takes the input TEC maps present at near (eg. at time resolution of one hour) and trend module takes the input TEC maps present at distant (eg. at time resolution of three hour) compared to the future TEC maps to be predicted. The input to the ST-ResNet model is a 3D volume / tensor of past TEC maps stacked behind each other. The output of the three branches are dynamically aggregated with weights learned during training for getting the final accurate prediction.

To obtain a contextual awareness of other space weather indicators during prediction, we integrate exogenous OMNI IMF data (By, Bz, Vx, Np) in an end-to-end fashion, through a Gated Recurrent Unit (GRU) encoder module in our model. GRU helps to process the IMF data in a sequential manner and combine with the ResNet outputs for getting the final prediction. The model architecture is shown in the figure below.

| ![]({{site.url}}/assets/st_resnet.png) |
|:--:| 
| **Figure 2: ST-ResNet Architecture** |

### Timeline 2: May 29 to June 11
* Setting up input data pipeline
* Creating TEC data points for the model
* Implementing ST-ResNet Architecture in Tensorflow

### TEC Data Points
We use the TEC data available in the text files. The TEC values for a particular date and time are extracted and stored as a 2D numpy array. The rows of the array corresponds to the magnetic latitudes and the columns corresponds to the magnetic longitudes. The pandas library is very useful in dealing with tabular data. The TEC data is read into the dataframe and the pivot function is used for selecting the required TEC values in the particular latitude-longitude range. All the TEC maps corresponding to date and time are created and then the sampling algorithm is used for creating the input data points. The number of input TEC maps for each of the ResNet modules are hyperparamters which will be set to accurate values after multiple trainings. As an example, one input data point will contain three different stack of TEC maps of size (12, 75, 73) for closeness module, (24, 75, 73) for period module and (8, 75, 73) for trend module. 

### Model Implementation 
We implement ST-ResNet model in Tensorflow following OOPs paradigm for better modularity. The complex model architecture parts are abstracted through extensive use of functions which brings in more flexibility and helps in coding Tensorflow functionality like sharing of tensors. There are four major files implemented are `main.py`, `params.py`, `modules.py` and `st_resnet.py`. 

File structure and details:
* `main.py`: This file contains the main program. The computation graph for ST-ResNet is built and launched in a session.
* `params.py`: This file contains class Params for hyperparameter declarations.
* `modules.py`: This file contain helper functions and custom neural layers. The functions help in abstracting the complexity of the architecture and Tensorflow features. These functions get called for defining the entire computational graph.
* `st_resnet.py`: This file defines the Tensorflow computation graph for the ST-ResNet architecture. The skeleton of the architecture from inputs to outputs is defined here using calls to functions defined in modules.py. Modularity ensures that the functioning of a component can be easily modified in modules.py without changing the skeleton of the ST-ResNet architecture defined in this file.

The complete code for the model in Tensorflow is available at the GitHub Repository [DeepPredTEC](https://github.com/vtsuperdarn/DeepPredTEC).  

### Timeline 3: June 12 to June 17
* Improving data pipeline  
* Fine tuning the ST-ResNet model and plotting the results

The data input files size is very large and we need an effective way of loading the data inputs as a batch to be able to train the model. We explore the yield function of python and also sqlite3 database for easy storing and retriving of TEC Maps. 

The ST-ResNet model is trained using `AdamOptimizer` function of Tensorflow. We report preliminary results on predicting the next TEC map by training the model on a small subset of the TEC data. Sample output predicted by the model is shown in the figures below. 

Sample with a comparatively lower loss (left figure is the predicted TEC map and the right one is the ground truth):

| ![]({{site.url}}/assets/output1.png) |
|:--:| 
| **Figure 3: Future TEC Prediction on a Date and Time Near Training Data Points** |

Sample with a comparatively higher loss(left figure is the predicted TEC map and the right one is the ground truth):

| ![]({{site.url}}/assets/output2.png) |
|:--:| 
| **Figure 4: Future TEC Prediction on a Date and Time Farther from Training Data Points** |

## Presentation Slides
TODO

## Phase 2
The major focus in the second phase of the project is on getting a better understanding of the model through plotting of intermediate outputs and results. Results are also analysed before and after integration of IMF data processed through GRU network. The models scalability is analysed by predicting the TEC maps for the next one hour at a time resolution of five minutes.     

### Timeline 4: June 18 to June 26
* Getting the difference and channel wise TEC map plots
* Error plots based on difference plots for further analysis

### Difference Plots 
The model was completely implemented in Tensorflow. Without considersing the exogenous module, the model is trained on a fraction of the dataset and the accuracy are reported in a qualitative manner. The predicted maps are plotted and the results are analysed by looking at the absolute and relative difference at each location between the true TEC map and predicted TEC map. The sample predicted plot along with the difference plots is given below.

| ![]({{site.url}}/assets/difference.png) |
|:--:| 
| **Figure 5: Difference Plot Between the True and Predicted TEC Map Without IMF** |
 
### Channel Wise Output Plots
Not only the final output, but the output from each of the ResNet channels, closeness, period and trend, are also plotted for better understanding of the patterns that are being captured by the model. This also helps in evaluating the importance of each of the channels and will further help in model parameter tuning. The sample channel wise output plots for the predicted TEC map is given below.  

| ![]({{site.url}}/assets/channel.png) |
|:--:| 
| **Figure 6: Channel Wise Plot for a Sample Predicted TEC Map Without IMF** |
 
### Timeline 5: June 27 to July 4
* OMNI IMF data preprocessing
* Implementing GRU encoder module  
* Results comparison with and without exogenous module

### IMF data preprocessing
From the list of exogenous variables, only the IMF data including Bz (OMNI IMF z component), By (OMNI IMF y component), Vx which is the plasma bulk velocity in km/s along x-axis and Np which is the proton number density is taken as an input to the exogenous module. The IMF data is available in a sqlite3 database. Using the forward filling mechanism the missing rows corresponding to the date & time are filled and updated in the original database.

### GRU Encoder Module
The IMF data with preprocessing is given as an input to the exogenous module which is based on an GRU architecture. IMF data is loaded with a look back window which is initialized as one of the hyperparamters of the model. GRU takes the (Bz, By, Vx, Np) vectors in a sequential manner based on the date & time associated with it and outputs an abstract complex representation by considering the temporal dependencies present between them. 

### Improved Results with IMF data
The model is trained by considering the ResNet modules and the exogenous module. The output of the predicted TEC map is analysed with the integration of the IMF data. Results show that IMF data helps in more accurate and smooth prediction at majority of the locations. The sample predicted and difference plot after integration with IMF data is given below.

| ![]({{site.url}}/assets/exodifference.png) |
|:--:| 
| **Figure 5: Difference Plot Between the True and Predicted TEC Map With IMF** |
 
The channel wise output plots with the IMF data integration helps us to understand the change in behaviour of the channels after dynamic integration of channel outputs with the GRU output. It also helps us to understand the relationship between the TEC maps and the IMF data. The sample channel wise output plots with IMF data integration is given below.

| ![]({{site.url}}/assets/exochannel.png) |
|:--:| 
| **Figure 6: Channel Wise Plot for a Sample Predicted TEC Map With IMF** |
 
### Timeline 6: July 5 to July 9
* Modifying the code for predicting the next one hour (block) TEC maps
* Reporting the results on block prediction

### Block prediction (next one hour) 
The major aim of using the deep learning model for predicting TEC maps was to obtain a generalized and scalable model. Instead of predicting only the next TEC map, the model now tries solve the harder task of predicting the next one hour TEC maps at a time resolution of five minutes given the past TEC maps as the input. This helps us in understanding the model's scalability and will further help us in tuning the input TEC maps to each of the channels. On a minimally trained model the accuracy results are reported. The sample block (next one hour) predicted TEC maps are given below. 

TODO image 
  
## Presentation Slides
TODO

## Phase 3

## Future Work

## References
* [https://github.com/vtsuperdarn/DeepPredTEC](https://github.com/vtsuperdarn/DeepPredTEC)
* [https://www.haystack.mit.edu/atm/open/radar/index.html](https://www.haystack.mit.edu/atm/open/radar/index.html)
* [Zhang, Junbo, Yu Zheng, and Dekang Qi. "Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction." AAAI. 2017.](https://arxiv.org/pdf/1610.00081.pdf)
