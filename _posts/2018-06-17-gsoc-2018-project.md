---
layout: post
title: GSOC 2018 Project
date: 2018-06-17
---
## Title
Building Deep Predictive Models for Predicting GPS TEC Maps

## Contents
<ol class="task-list">
<li> GSoC 2018 Project

    <ul class="task-list">
    <li>Abstract</li>
    <li>Broad Steps</li>
    </ul>
    </li>

<li> People</li>

<li> Infrastructure</li>

<li> Phase 1
    <ul class="task-list">
    <li>Timeline 1: May 14 to May 28</li>
    <li>Timeline 2: May 29 to June 11</li>
    <li>Timeline 3: June 12 to June 17</li>
    </ul>
    </li>

<li> Phase 2</li>
<li> Phase 3</li>
<li> Future Work</li>
<li> References</li>
</ol>

## Abstract
GPS TEC Map (Global Positioning System - Total Electron Count) is an important quantity of the ionosphere for analysis of space weather. Building an accurate predictive model for TEC maps can help in anticipating adverse ionospheric effects (ex: due to a solar storm), thereby safeguarding critical communication, energy and navigation infrastructure. In this work, we employ a deep learning approach to predict TEC maps using deep Spatio-Temporal Residual Networks (ST-ResNets), the first attempted work of its kind, by focusing on the North American region. To obtain a contextual awareness of other space weather indicators during prediction, we also use exogenous data including OMNI IMF data (By, Bz, Vx, Np). Our model predicts TEC maps for the next hour and beyond, at a time resolution of five minutes, providing state-of-the-art prediction accuracy. Towards explainable Artificial Intelligence (AI), especially in deep learning models, we provide extensive visualizations of the outputs from our convolutional networks in all three branches (closeness, period and trend) for better analysis and insight. In the future, we aim to demonstrate the effectiveness and robustness of our model in predicting extremely rare solar storms, a challenging task given the insufficient training data for such events.

## Project Outline
<table>
<thead>
<tr>
<th>S.No.</th>
<th>Step</th>
<th>Status</th>
<th>Date</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Dataset exploration: plotting TEC</td>
<td> <span style="color:green"> DONE </span> </td>
<td>May 14</td>
</tr>
<tr>
<td>2</td>
<td>Dataset preprocessing: missing values</td>
<td> <span style="color:green"> DONE </span> </td>
<td>May 24</td>
</tr>
<tr>
<td>3</td>
<td>Input pipeline: closeness, period, trend</td>
<td> <span style="color:green"> DONE </span> </td>
<td>May 28</td>
</tr>
<tr>
<td>4</td>
<td>Model: ST-ResNet in Tensoflow</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 2</td>
</tr>
<tr>
<td>5</td>
<td>Model debugging</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 12</td>
</tr>
<tr>
<td>6</td>
<td>Results & plots of output TEC maps</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 12</td>
</tr>
<tr>
<td>7</td>
<td>Channel wise TEC map plots</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 19</td>
</tr>
<tr>
<td>8</td>
<td>Error plots for analysis</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 22</td>
</tr>
<tr>
<td>9</td>
<td>IMF data preprocessing</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 26</td>
</tr>
<tr>
<td>10</td>
<td>Model: Encoder LSTM</td>
<td> <span style="color:green"> DONE </span> </td>
<td>June 26</td>
</tr>
<tr>
<td>11</td>
<td>Improved Results with IMF data</td>
<td> <span style="color:green"> DONE </span> </td>
<td>July 4</td>
</tr>
<tr>
<td>12</td>
<td>Block prediction (next 12)</td>
<td> <span style="color:green"> DONE </span> </td>
<td>July 9</td>
</tr>
</tbody>
</table>

## People 
<ul>
<li>Sneha Singhania (sneha3295[at]gmail[dot]com)</li>
<li>Bharat Kunduri (bharatr[at]vt[dot]edu)</li>
<li>Muhammad Rafiq (rafiq[at]vt[dot]edu)</li>
</ul> 

## Infrastructure
We have used the HPCC system available at Virginia Tech for training the deep learning models on the entire dataset and Google Colab free GPU for training the model on a very small sample of the dataset. I'm highly thankful to the Space@VT organisation for arranging such a high end resource which was very helpful for training and testing various models.

## Phase 1

### Timeline 1: May 14 to May 28
* Read about GPS TEC Maps, IMF data and other geomagnetic indices  
* Plotting the TEC Maps
* Discussion on the specifications of ST-ResNet Architecture

### GPS TEC Maps
TEC is the total number of electrons integrated between two points, along a tube of one meter squared cross section. It is a descriptive quantity for the ionosphere of the Earth atmosphere. It can be used for anticipating adverse ionospheric events like solar storms. For this project, we use GPS TEC Maps provided by the MIT Haystack Observatory (Madrigal database). This data is further pre-processed using techniques like median filtering. The TEC maps in its original form and in pre-processed form using median filtering is available at the SuperDARN database of Virginia Tech. For our project, we focus using the median filtered TEC maps. 

The TEC maps are stored in a tablular format in text file format. The major columns present in the data are datetime, magnetic latitude, magnetic longitude, TEC values, degree of magnetic latitude resolution and degree of magnetic longitude resoltion. The TEC values are recorded at a resolution of five minutes. We focus on the North-American sector of the TEC maps whose magnetic latitude lies in the range [15, 89] and magnetic longitude lies in the range [250, 360] and [0, 34]. From each text file, we read the TEC values in the given ranges and store it in separate numpy arrays of shape (75, 73).

We also plot TEC maps using the matplotlib library for better understanding. Visualization of TEC maps helps in understanding the spatial and temporal patterns and using them for further designing the deep learning models. A sample plot of TEC map is shown in the figure below.

![Sample TEC Plot2]({{site.url}}/assets/sample_tec.png)

Apart from the GPS TEC maps we also plan to use other exogenous variables for better model prediction. The list of exogenous variables are as follows:
* AU index, AL index (Auroral index horizontal component disturbances)
* Sym-H index, AsyH index (longitudinally symmetric/asymmetric disturbance index)
* Bz - OMNI IMF z component
* By - OMNI IMF y component
* Vx, np (proton ratio), f10.7 (daily flux density), dipole tilt


## Motivation 
We use deep learning models because of the availability of large scale input TEC maps and presence of complex dependencies (correlation) between the time series TEC Maps. TEC maps are two dimensional which provides the spatio properties and the time series nature between the TEC maps brings in the temporal property. Using these properties we design our first model called Spatio-Temporal Residual Networks.

## ST-ResNet Architecture
Spatio-Temporal Residual Networks (ST-ResNet) is a deep learning model build using Residual Networks which are a better variant of Convolutional Neural Networks (CNNs). The original Residual Network (ResNet) is a 152 layer network architecture which is used for classification, detection, and localization of objects. It won ImageNet Large Scale Visual Recognition Competition (ILSVRC) 2015 challenge. In general with increasing depth, neural networks suffer from vanishing gradient problem. Residual links in the network overcomes this problem. Deep residual networks helps in creating complex and abstract features.


The input to the ST-ResNet model is a 3D volume / tensor of past TEC maps stacked on top of each other. Residual Networks in the model captures the spatial dependency within each individual tec map by convolving along the width and height axes of the TEC maps. The key observation is that a convolution along the depth axis captures temporal dependency since the depth axis is considered as the time variable.

Further, the above model is replicated three times to capture temporal dependencies, classified as closeness(recent), period(near) and trend(distant), each with an increasing time period of repetition. The previous immediate 12 TEC maps which are at a time resolution of 5 mins in the span of one hour forms the input for closeness module. The previous TEC maps at a time resoltion of one hour over the span of one day (24 in total) forms the input for period module. Finally, the TEC maps over the span of one previous day at a time resolution of three hours (8 in total) forms in the input for trend module.

Along with the Residual Network modules, for closeness, period and trend, we have a module for handling the IMF (exogenous) data. The module is based on Long-Short Term Memory (LSTM) which is further integrated with the main architecture for boosting the effectiveness of the feature vector. The model architecture is shown in the figure below.

![ST-ResNet Architecture]({{site.url}}/assets/st_resnet.png)

## Timeline 2: May 29 to June 11
* Setting up input data pipeline
* Creating TEC data points for the model
* Implementing ST-ResNet Architecture in Tensorflow

We create data inputs from the given .txt files of TEC maps. We first read and extract the TEC values and store them as 2D matrices. The rows of the matrix represents the latitudes and the columns represent the longitudes. We make of pandas dataframe to read the values from .txt file and use the pivot function on the dataframe object for selecting the required TEC values. Once we get all TEC maps in matrix format we run the sampling algorithm for creating the data inputs. The number of input TEC maps for each of the ResNet modules are hyperparamters which will be tuned later. As an example, one data input consists of three different stack of TEC maps of size (12, 75, 73) as closeness input, (24, 75, 73) as period input and (8, 75, 73) as trend input. 

We have implemented ST-ResNet model in Tensorflow. The model is coded by following OOPs paradigm. The complex model architecture parts are abstracted through extensive use of functions which brings in more flexibility and helps in coding Tensorflow functionality like sharing of tensors. There are four major files `main.py`, `params.py`, `modules.py` and `st_resnet.py` which are implemented. 

File structure and details:
* `main.py`: This file contains the main program. The computation graph for ST-ResNet is built and launched in a session.
* `params.py`: This file contains class Params for hyperparameter declarations.
* `modules.py`: This file contain helper functions and custom neural layers. The functions help in abstracting the complexity of the architecture and Tensorflow features. These functions are being called in the st_resnet.py for defining the computational graph.
* `st_resnet.py`: This file defines the Tensorflow computation graph for the ST-ResNet (Deep Spatio-temporal Residual Networks) architecture. The skeleton of the architecture from inputs to outputs in defined here using calls to functions defined in modules.py. Modularity ensures that the functioning of a component can be easily modified in modules.py without changing the skeleton of the ST-ResNet architecture defined in this file.

The complete code for the model in Tensorflow is available at the GitHub Repository DeepPredTEC.  

### Timeline 3: June 12 to June 17
* Improving data pipeline  
* Fine tuning the ST-ResNet model and plotting the results

The data input files size is very large and we need an effective way of loading the data inputs as a batch to be able to train the model. We explore the yield function of python and also sqlite3 database for easy storing and retriving of TEC Maps. 

The ST-ResNet model is trained using `AdamOptimizer` function of Tensorflow. Currently the model has been trained on a small subset of the data points. Sample output predicted by the model is shown in the figures below. 

Sample with a comparatively lower loss (left figure is the predicted TEC map and the right one is the ground truth):

![Prediction Output on a recent day]({{site.url}}/assets/output1.png)

Sample with a comparatively higher loss(left figure is the predicted TEC map and the right one is the ground truth):

![Prediction Output on a later day]({{site.url}}/assets/output2.png)

## Presentation Slides


## References
* [https://github.com/vtsuperdarn/DeepPredTEC](https://github.com/vtsuperdarn/DeepPredTEC)
* [https://www.haystack.mit.edu/atm/open/radar/index.html](https://www.haystack.mit.edu/atm/open/radar/index.html)
* [Zhang, Junbo, Yu Zheng, and Dekang Qi. "Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction." AAAI. 2017.](https://arxiv.org/pdf/1610.00081.pdf)
